{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode\n",
    "from teste_eng_dados_lambda.setup import desafio_engenheiro\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação:\n",
    "Para que as tarefas 1 e 2 pudessem ser feitas e depois avaliadas com um setup mínimo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DesafioEngenheiro\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = desafio_engenheiro(spark=spark).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cliente :\n",
      "+----------+---------+\n",
      "|cliente_id|     nome|\n",
      "+----------+---------+\n",
      "|         1|Cliente A|\n",
      "|         2|Cliente B|\n",
      "|         3|Cliente C|\n",
      "|         4|Cliente D|\n",
      "+----------+---------+\n",
      "\n",
      "contrato :\n",
      "+-----------+-----+----------+----------+\n",
      "|contrato_id|ativo|percentual|cliente_id|\n",
      "+-----------+-----+----------+----------+\n",
      "|          1| true|       2.0|         1|\n",
      "|          2|false|      1.95|         1|\n",
      "|          3| true|       1.0|         2|\n",
      "|          4| true|       3.0|         4|\n",
      "+-----------+-----+----------+----------+\n",
      "\n",
      "transacao :\n",
      "+------------+-----------+-----------+-------------------+\n",
      "|transacao_id|contrato_id|valor_total|percentual_desconto|\n",
      "+------------+-----------+-----------+-------------------+\n",
      "|           1|          1|     3000.0|               6.99|\n",
      "|           2|          2|     4500.0|               15.0|\n",
      "|           3|          1|    57989.0|               1.45|\n",
      "|           4|          4|        1.0|               null|\n",
      "|           5|          4|       35.0|               null|\n",
      "+------------+-----------+-----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('cliente :')\n",
    "spark.sql(\"SELECT * FROM cliente\").show()\n",
    "print('contrato :')\n",
    "spark.sql(\"SELECT * FROM contrato\").show()\n",
    "print('transacao :')\n",
    "spark.sql(\"SELECT * FROM transacao\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa  1 & 2: \n",
    "### Tarefa 1:\n",
    "Escrever uma aplicação para calcular o ganho total da empresa, o qual é obtido a partir da taxa administrativa do serviço de cartão de crédito para seus clientes. Esse ganho é calculado sobre um percentual das transações de cartão de crédito realizadas por eles.\n",
    "### Tarefa 2:\n",
    "Calcular o total líquido da empresa. Esse total é calculado da seguinte forma total_liquido = soma(total_bruto – desconto_percentual)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa célula é criada uma tabela que consulta que reúne os dados das três tabelas de fonte em uma única que podemos usar para executar os cálulos necessários e observar alguns detalhes:\n",
    "* 'Cliente C' não terá participação no ganho total da empresa, pois não possível contrato e por isso não posui transações.\n",
    "* 'Cliente B' não terá participação no ganho total da empresa, pois por mais que tenha contrato, não possui transações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Componentes Gerais de Cálculo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:=================================>                       (7 + 5) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------+-----+-----------+----------+-------------------+-------------------+---------------------+\n",
      "|transacao_id|nome_cliente|contrato_id|ativo|valor_total|percentual|percentual_desconto|ganho_total_empresa|total_liquido_cliente|\n",
      "+------------+------------+-----------+-----+-----------+----------+-------------------+-------------------+---------------------+\n",
      "|           1|   Cliente A|          1| true|     3000.0|       2.0|               6.99|               60.0|               2790.3|\n",
      "|           2|   Cliente A|          2|false|     4500.0|      1.95|               15.0|              87.75|               3825.0|\n",
      "|           3|   Cliente A|          1| true|    57989.0|       2.0|               1.45|            1159.78|           57148.1595|\n",
      "|           4|   Cliente D|          4| true|        1.0|       3.0|                0.0|               0.03|                  1.0|\n",
      "|           5|   Cliente D|          4| true|       35.0|       3.0|                0.0|               1.05|                 35.0|\n",
      "+------------+------------+-----------+-----+-----------+----------+-------------------+-------------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('Componentes Gerais de Cálculo:')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "    C.transacao_id,\n",
    "    D.nome_cliente,\n",
    "    D.contrato_id,\n",
    "    D.ativo,\n",
    "    C.valor_total,\n",
    "    D.percentual,\n",
    "    CASE \n",
    "        WHEN C.percentual_desconto <> 0 then C.percentual_desconto\n",
    "        ELSE 0\n",
    "    END AS percentual_desconto,\n",
    "    C.valor_total*(D.percentual*0.01) as ganho_total_empresa,\n",
    "    CASE \n",
    "        WHEN C.percentual_desconto <> 0 then C.valor_total*(100-C.percentual_desconto)*0.01\n",
    "        ELSE C.valor_total\n",
    "    END AS total_liquido_cliente\n",
    "FROM transacao C\n",
    "INNER JOIN (\n",
    "    SELECT\n",
    "        B.*,\n",
    "        A.nome as nome_cliente\n",
    "    FROM cliente A\n",
    "    INNER JOIN contrato B ON A.cliente_id = B.cliente_id\n",
    "    --where ativo = True\n",
    ") D ON C.contrato_id = D.contrato_id\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um observação a ser feita é que existem três contratos para 'Cliente A', porêm somente dois tem o status de ativo, como pode ser visto pela coluna 'ativo'. Como não foi específicado se essa diferenciação é necessária os valores foram calculados considerando os dois casos:\n",
    "* Todos os contratos.\n",
    "* Somente contratos ativos.\n",
    "A justificativa para isso é que a depender do intervalo de tempo em que se busca analisar o ganho financeiro, contratos não ativos podem ser relevantes, pois tal contrato poderia estar ativo durante aquele período específico de tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados Finais:\n",
      "Considerando todos os contratos:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+---------------------+\n",
      "|nome_cliente|ganho_total_empresa|total_liquido_cliente|\n",
      "+------------+-------------------+---------------------+\n",
      "|   Cliente A|            1307.53|   63763.459500000004|\n",
      "|   Cliente D|               1.08|                 36.0|\n",
      "+------------+-------------------+---------------------+\n",
      "\n",
      "Considerando somente contratos ativos :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+---------------------+\n",
      "|nome_cliente|ganho_total_empresa|total_liquido_cliente|\n",
      "+------------+-------------------+---------------------+\n",
      "|   Cliente A|            1219.78|   59938.459500000004|\n",
      "|   Cliente D|               1.08|                 36.0|\n",
      "+------------+-------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Dados Finais:')\n",
    "print('Considerando todos os contratos:')\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        nome_cliente,\n",
    "        SUM(ganho_total_empresa) as ganho_total_empresa,\n",
    "        SUM(total_liquido_cliente) as total_liquido_cliente\n",
    "    FROM (SELECT\n",
    "        nome_cliente,\n",
    "        SUM(valor_total)*percentual*0.01 as ganho_total_empresa,\n",
    "        CASE \n",
    "            WHEN C.percentual_desconto <> 0 then SUM(C.valor_total)*(100-C.percentual_desconto)*0.01\n",
    "            ELSE SUM(C.valor_total)\n",
    "        END AS total_liquido_cliente\n",
    "    FROM transacao C\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            B.*,\n",
    "            A.nome as nome_cliente\n",
    "        FROM cliente A\n",
    "        INNER JOIN contrato B ON A.cliente_id = B.cliente_id\n",
    "        --where ativo = True\n",
    "    ) D ON C.contrato_id = D.contrato_id\n",
    "    GROUP BY nome_cliente, percentual, percentual_desconto)\n",
    "GROUP BY nome_cliente\n",
    "\"\"\").show()\n",
    "print('Considerando somente contratos ativos :')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        nome_cliente,\n",
    "        SUM(ganho_total_empresa) as ganho_total_empresa,\n",
    "        SUM(total_liquido_cliente) as total_liquido_cliente\n",
    "    FROM (SELECT\n",
    "        nome_cliente,\n",
    "        SUM(valor_total)*percentual*0.01 as ganho_total_empresa,\n",
    "        CASE \n",
    "            WHEN C.percentual_desconto <> 0 then SUM(C.valor_total)*(100-C.percentual_desconto)*0.01\n",
    "            ELSE SUM(C.valor_total)\n",
    "        END AS total_liquido_cliente\n",
    "    FROM transacao C\n",
    "    INNER JOIN (\n",
    "        SELECT\n",
    "            B.*,\n",
    "            A.nome as nome_cliente\n",
    "        FROM cliente A\n",
    "        INNER JOIN contrato B ON A.cliente_id = B.cliente_id\n",
    "        where ativo = True\n",
    "    ) D ON C.contrato_id = D.contrato_id\n",
    "    GROUP BY nome_cliente, percentual, percentual_desconto)\n",
    "GROUP BY nome_cliente\n",
    "\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores contidos no reposítório da proposta do teste para essa questão eram especificamente:\n",
    "* Cliente A : 1198.77\n",
    "* Cliente B : 1.08\n",
    "\n",
    "O valor das respostas encontradas não foi compatível com o que foi disponibilizado. No caso do Cliente B, os dados apontam que ele não contibuí para o resultado, além disso vimos que o valor atribuído a ele é idêntico ao valor calculado para 'Cliente D'. Para o caso do 'Cliente A' não foi possível encontrar evidências que o valor informado seja possível de se obter com essa base de dados, idependente de quais contratos sejam considerados. \n",
    "\n",
    "A regra usada para definir a Taxa de Administração foi a seguinte:\n",
    "\n",
    "$Taxa = valor_{total}\\cdot percentual$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Líquido de todos os contratos:  63763.46\n",
      "Total Líquido de todos os contratos ativos:  59938.46\n"
     ]
    }
   ],
   "source": [
    "df_liquido_todos = spark.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "    valor_total, percentual_desconto\n",
    "FROM transacao\n",
    "\"\"\"\n",
    ")\n",
    "df_liquido_ativo = spark.sql(\n",
    "    \"\"\"\n",
    "SELECT\n",
    "    valor_total, percentual_desconto\n",
    "FROM transacao A\n",
    "INNER JOIN contrato B ON A.contrato_id = B.contrato_id\n",
    "WHERE ativo = True\n",
    "\"\"\"\n",
    ")\n",
    "total_liquido_todos = (df_liquido_todos\n",
    "                .withColumn(\"total_liquido_cliente\", col(\"valor_total\") *(100 -  col(\"percentual_desconto\"))*0.01)\n",
    "                .agg({\"total_liquido_cliente\": \"sum\"}).collect()[0][0])\n",
    "total_liquido_ativo = (df_liquido_ativo\n",
    "                .withColumn(\"total_liquido_cliente\", col(\"valor_total\") *(100 -  col(\"percentual_desconto\"))*0.01)\n",
    "                .agg({\"total_liquido_cliente\": \"sum\"}).collect()[0][0])\n",
    "print(f\"Total Líquido de todos os contratos: {total_liquido_todos : .2f}\")\n",
    "print(f\"Total Líquido de todos os contratos ativos: {total_liquido_ativo : .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividade 3:\n",
    "O terceiro entregável consiste na transformação de dados disponíveis em arquivo Json para o formato de dataframe, algo comum no dia a dia da empresa. Após transformar esse Json em dataframe é possível perceber que a coluna \"item_list\" está como dicionário. Seu gestor pediu dois pontos de atenção nessa tarefa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_files/json/data_nfe.json', 'r') as json_file:\n",
    "    data_nfe = json.load(json_file)\n",
    "    json_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expandir a coluna num mesmo dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame em seu estado \"RAW\":\n",
      "+--------------------+--------+-------------------+--------------------+-----+---------+\n",
      "|          CreateDate|Discount|       EmissionDate|            ItemList|NFeID|NFeNumber|\n",
      "+--------------------+--------+-------------------+--------------------+-----+---------+\n",
      "|2021-05-24T20:21:...|     0.0|2021-05-24T00:00:00|[{Value -> 35.55,...|    1|      501|\n",
      "|2021-05-24T20:21:...|     0.0|2021-05-24T00:00:00|[{Value -> 12.25,...|    2|      502|\n",
      "|2021-05-24T20:21:...|     0.0|2021-05-24T00:00:00|[{Value -> 9.0, Q...|    3|      503|\n",
      "+--------------------+--------+-------------------+--------------------+-----+---------+\n",
      "\n",
      "DataFrame com coluna \"ItemList\" expandida\n",
      "+--------------------+-------------------+--------+---------+-----+------------+-----+--------+\n",
      "|          CreateDate|       EmissionDate|Discount|NFeNumber|NFeID| ProductName|Value|Quantity|\n",
      "+--------------------+-------------------+--------+---------+-----+------------+-----+--------+\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|     0.0|      501|    1|        Rice|35.55|       2|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|     0.0|      501|    1|       Flour|11.55|       5|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|     0.0|      501|    1|        Bean|27.15|       7|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|     0.0|      502|    2|      Tomate|12.25|      10|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|     0.0|      502|    2|       Pasta| 7.55|       5|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|     0.0|      503|    3|        Beer|  9.0|       6|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|     0.0|      503|    3|French fries|10.99|       2|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|     0.0|      503|    3|   Ice cream|27.15|       1|\n",
      "+--------------------+-------------------+--------+---------+-----+------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data_nfe)\n",
    "print('DataFrame em seu estado \"RAW\":')\n",
    "df.show()\n",
    "df_expanded = (df.select(\n",
    "    \"CreateDate\",\n",
    "    \"EmissionDate\",\n",
    "    \"Discount\",\n",
    "    \"NFeNumber\",\n",
    "    \"NFeID\",\n",
    "    explode(\"ItemList\").alias(\"Item\")\n",
    ").select(\n",
    "    \"CreateDate\",\n",
    "    \"EmissionDate\",\n",
    "    \"Discount\",\n",
    "    \"NFeNumber\",\n",
    "    \"NFeID\",\n",
    "    col(\"Item.ProductName\").alias(\"ProductName\"),\n",
    "    col(\"Item.Value\").alias(\"Value\"),\n",
    "    col(\"Item.Quantity\").alias(\"Quantity\")\n",
    "))\n",
    "print('DataFrame com coluna \"ItemList\" expandida')\n",
    "df_expanded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar os itens dessa coluna de dicionário e dividí-los em dois dataframes separados, seguindo o modelo relacional:\n",
    "A separação ocorrerá em três tabelas que serão organizadas da seguinte forma:\n",
    "* NFE:\n",
    "    * CreateDate\n",
    "    * EmissionDate\n",
    "    * Discount\n",
    "    * NFeNumber\n",
    "    * NFeID\n",
    "* Sales:\n",
    "    * NFeID\n",
    "    * ProductName\n",
    "    * Quantity\n",
    "* Products:\n",
    "    * ProductName\n",
    "    * Value\n",
    "Exemplos de como essas tabelas ficariam podem ser vistos abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFE:\n",
      "+--------------------+-------------------+---------+-----+--------+\n",
      "|          CreateDate|       EmissionDate|NFeNumber|NFeID|Discount|\n",
      "+--------------------+-------------------+---------+-----+--------+\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|      501|    1|     0.0|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|      502|    2|     0.0|\n",
      "|2021-05-24T20:21:...|2021-05-24T00:00:00|      503|    3|     0.0|\n",
      "+--------------------+-------------------+---------+-----+--------+\n",
      "\n",
      "Sales:\n",
      "+-----+------------+--------+\n",
      "|NFeID| ProductName|Quantity|\n",
      "+-----+------------+--------+\n",
      "|    1|        Rice|       2|\n",
      "|    1|       Flour|       5|\n",
      "|    1|        Bean|       7|\n",
      "|    2|      Tomate|      10|\n",
      "|    2|       Pasta|       5|\n",
      "|    3|        Beer|       6|\n",
      "|    3|French fries|       2|\n",
      "|    3|   Ice cream|       1|\n",
      "+-----+------------+--------+\n",
      "\n",
      "Products:\n",
      "+------------+-----+\n",
      "| ProductName|Value|\n",
      "+------------+-----+\n",
      "|        Bean|27.15|\n",
      "|        Rice|35.55|\n",
      "|       Flour|11.55|\n",
      "|      Tomate|12.25|\n",
      "|       Pasta| 7.55|\n",
      "|        Beer|  9.0|\n",
      "|French fries|10.99|\n",
      "|   Ice cream|27.15|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_NFE = df_expanded.select(\n",
    "    \"CreateDate\",\n",
    "    \"EmissionDate\",\n",
    "    \"NFeNumber\",\n",
    "    \"NFeID\",\n",
    "    \"Discount\").distinct()\n",
    "print('NFE:')\n",
    "df_NFE.show()\n",
    "df_sales = df_expanded.select(\n",
    "    \"NFeID\",\n",
    "    \"ProductName\",\n",
    "    \"Quantity\")\n",
    "print('Sales:')\n",
    "df_sales.show()\n",
    "df_products = df_expanded.select(\n",
    "    \"ProductName\",\n",
    "    \"Value\").distinct()\n",
    "print('Products:')\n",
    "df_products.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante ressaltar que em um ambiente em produção a tabela 'Products' é atualizada separadamente, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teste-eng-dados-lambda-2WcI74M4-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
